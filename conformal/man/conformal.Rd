\docType{package}
\name{conformal}
\alias{conformal}
\alias{conformal-package}
\title{conformal: an R package to calculate prediction errors in the conformal prediction framework}
\description{
conformal permits the calculation of prediction errors in the conformal prediction framework:
(i) p.values for classification, and
(ii) confidence intervals for regression.
The package are based on R reference classes (OOP).
}

\details{
Assessing the reliability of individual predictions 
is foremost in machine learning to determine the applicability domain of a predictive model, be it in the context of classification or regression.
The applicability domain is usually defined as the amount (and thus regions) of descriptor space to which a model can be reliably applied.
Conformal prediction is an algorithm-independent technique, i.e. it works with any predictive method such as SVM, PLS, etc..,
which outputs confidence regions for individual predictions in the case of regression,
and p.values for the categories in classification.
\cr

\bold{Regression}

In regression, the confidence level, \eqn{\epsilon}, is controlled by the user, and thus the interpretation is straightforward.
For instance, it we choose a confidence level of 80\%
the true value for new datapoints will lie outside the predicted confidence intervals 
in at most 20\% of the cases.

In the conformal prediction framework, the datapoints in the training set are used to define how unlikely a new datapoint is with respect to the data presented to the model in the training phase. 
The conformity for a given datapoint, \eqn{x_i}, with respect to the training set is quantified with a nonconformity score, \eqn{\alpha},
calculated with a nonconformity measure (e.g. \code{\link{StandardMeasure}}),
which here we define as:

\eqn{$\alpha_{i} = \frac {|y_{i}-\widetilde{y}_{i}|}  {\widetilde{\rho}_{i}}$}


where \eqn{\alpha_{i}} is the nonconformity measure,
\eqn{y_{i}} and \eqn{\widetilde{y}_{i}} are respectively the the observed and the predicted value
calculated with an error model,
and \eqn{\widetilde{\rho}_{i}}
is the predicted error for \eqn{x_i} calculated with an error model.
The nonconformity scores are then translated into a confidence region for a user-defined confidence level, \eqn{\epsilon}.
\cr
In order to calculate confidence intervals, we need a point prediction model, 
to predict the response variable (\eqn{y}), and an error model, to predict errors in prediction (\eqn{\widetilde{\rho}}). 
The point prediction and error models can be generated with any machine learning algorithm, hence algorithm-independent (see above).
Both the point prediction and error models need to be trained with cross-validation in order to calculate the vector of nonconformity
scores for the training set.
\cr
The cross-validation predictions generated when training the point prediction model 
serve to calculate the errors in prediction for the datapoints in the training set. 
The error model is then generated by training a machine learning model on the training set 
using these errors as the dependent variable. 
The (i) cross-validated predictions from the point prediction model, 
and (ii) the cross-validated errors in prediction from the error model,
are used to generate the vector of nonconformity scores for the training set. 
This vector, after being sorted in increasing order, can be defined as:

\eqn{$\alpha_{training} = \{\alpha_{training\ i}\}^{N_{training}}_{i}$}  
where \eqn{N_{training}} is the number of datapoints in the training set.

To generate the confidence intervals for an external set, 
the \eqn{\alpha} value associated to the user-defined confidence level, \eqn{\alpha_{\epsilon}}, is calculated as:

\eqn{$ \alpha_{\epsilon} = \alpha_{training\ i} \ \  if \ \  i \equiv |N_{training} * \epsilon| $}

where \eqn{\equiv} indicates equality. 
Next, the errors in prediction, \eqn{\widetilde{\rho}_{ext}}, 
and the value for the response variable, \eqn{y_{ext}},
for the datapoints in an external dataset
	are predicted with the error and the point prediction models, respectively.

Individual confidence intervals for each datapoint in the external set are calculated as:
\eqn{$ |y_{ext} - \widetilde{y}_{ext}|   =  \alpha_{\epsilon} * \widetilde{\rho}_{ext} $}


\bold{Classification}

In the case of classification, the predictions of the trees in a Random Forest model
serve to calculate class probabilities (p.values).
Firstly, a Random Forest classifier is trained on a dataset using cross-validation.
For each datapoint, the percentage of trees in the forest 
that predict a given class is calculated.
This process generates as many vectors of percentages as categories,
which are then sorted in increasing order. 

}
\references{
Isidro Cortes <isidrolauscher@gmail.com>.
conformal: an R package to calculate prediction errors in the conformal prediction framework.

Shafer et al. JMLR, 2008, 9, pp 371-421.
\url{http://machinelearning.wustl.edu/mlpapers/paper_files/shafer08a.pdf}

Norinder et al. J. Chem. Inf. Model., 2014, 54 (6), pp 1596-1603.
DOI: 10.1021/ci5001168
\url{http://pubs.acs.org/doi/abs/10.1021/ci5001168}

}

